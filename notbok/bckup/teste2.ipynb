{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f5fa352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aee8b4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'builder' from 'google.protobuf.internal' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\2\\ipykernel_6424\\3793406994.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunction_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\function_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# source: tensorflow/core/framework/function.proto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;34m\"\"\"Generated protocol buffer code.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_builder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdescriptor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_descriptor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdescriptor_pool\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_descriptor_pool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'builder' from 'google.protobuf.internal' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f938f512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19cc0b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2ad33c3b0a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tamanho da imagem do dataset MNIST\n",
    "img_shape = (1, 28, 28)\n",
    "\n",
    "# Criaço do DataLoader\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download = True, transform = transforms.Compose([transforms.ToTensor()])),\n",
    "    batch_size = 128,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16273046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bloco_gen_simples(dim_entrada, dim_saida, normalizar=True):\n",
    "    '''\n",
    "    Função responsável por construir uma camada da rede Geradora.\n",
    "    '''\n",
    "    camadas = [nn.Linear(dim_entrada, dim_saida)]\n",
    "    if normalizar:\n",
    "        camadas.append(nn.BatchNorm1d(dim_saida))\n",
    "    camadas.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "    return camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f551a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gerador(nn.Module):\n",
    "    '''\n",
    "    Classe que representa a rede Geradora.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, dim_ruido = 64, dim_img = 784, dim_oculta = 128):\n",
    "        '''\n",
    "        Função de criação da rede.\n",
    "        '''\n",
    "        super(Gerador, self).__init__()\n",
    "        \n",
    "        self.modelo = nn.Sequential (\n",
    "            *bloco_gen_simples(dim_ruido, dim_oculta * 2, False),\n",
    "            *bloco_gen_simples(dim_oculta * 2, dim_oculta * 4),\n",
    "            *bloco_gen_simples(dim_oculta * 4, dim_oculta * 8),\n",
    "            nn.Linear(dim_oculta * 8, dim_img),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, ruido):\n",
    "        '''\n",
    "        Função responsável por fazer uma passagem do ruído por\n",
    "        toda a estrutura da rede gerando uma imagem na saída.\n",
    "        '''\n",
    "        return self.modelo(ruido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9bea1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bloco_disc_simples(dim_entrada, dim_saida, normalizar=True):\n",
    "    '''\n",
    "    Função responsável por construir uma camada da rede Discriminadora.\n",
    "    '''\n",
    "    camadas = [nn.Linear(dim_entrada, dim_saida)]\n",
    "    camadas.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "    camadas.append(nn.Dropout(0.3))\n",
    "    return camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494be3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminador(nn.Module):\n",
    "    '''\n",
    "    Classe que representa a rede Discriminadora.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, dim_img = 784, dim_oculta = 128):\n",
    "        '''\n",
    "        Função de criação da rede\n",
    "        '''\n",
    "        super(Discriminador, self).__init__()\n",
    "        \n",
    "        self.modelo = nn.Sequential (\n",
    "            *bloco_disc_simples(dim_img, dim_oculta * 4),\n",
    "            *bloco_disc_simples(dim_oculta * 4, dim_oculta * 2),\n",
    "            *bloco_disc_simples(dim_oculta * 2, dim_oculta),\n",
    "            nn.Linear(dim_oculta, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        '''\n",
    "        Função responsável por fazer uma passagem da imagem pela rede\n",
    "        tendo como saída predição. (0 para imagens falsas e 1 para\n",
    "        imagens reais).\n",
    "        '''\n",
    "        return self.modelo(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d9afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterio = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b6e4b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerador_ruido(num_amostras, dim_ruido):\n",
    "    '''\n",
    "    Função utilizada para gerar um ruído aleatório.\n",
    "    '''\n",
    "    return torch.randn((num_amostras, dim_ruido), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58fb50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perda_gen(discriminador, gerador, criterio, tam_batch):\n",
    "    '''\n",
    "    Função que calcula a perda da rede Geradora.\n",
    "    '''\n",
    "    # geração do ruído\n",
    "    ruido = gerador_ruido(tam_batch, 64)\n",
    "    \n",
    "    # geração das imagens falsas\n",
    "    imgs_falsas = gerador(ruido)\n",
    "    \n",
    "    # classificação do Discriminador para as imagens falsas\n",
    "    disc_predicao_falsas = discriminador(imgs_falsas)\n",
    "    \n",
    "    # cálculo da perda\n",
    "    g_perda = criterio(disc_predicao_falsas, torch.ones_like(disc_predicao_falsas, device=device))\n",
    "    \n",
    "    return g_perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba9ffd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perda_disc(discriminador, gerador, criterio, tam_batch, imgs_real):\n",
    "    '''\n",
    "    Função que calcula a perda da rede Discriminadora.\n",
    "    '''\n",
    "    # geração do ruído\n",
    "    ruido = gerador_ruido(tam_batch, 64)\n",
    "    \n",
    "    # geraço das imagens falsas\n",
    "    imgs_falsas = gerador(ruido)\n",
    "    \n",
    "    # Predição para as imagens falsas e cálculo da perda 1\n",
    "    disc_predicao_falsas = discriminador(imgs_falsas.detach())\n",
    "    falsas_perda = criterio(disc_predicao_falsas, torch.zeros_like(disc_predicao_falsas, device=device))\n",
    "    \n",
    "    # Predição para as imagens reais e cálculo da perda 2\n",
    "    disc_predicao_real = discriminador(imgs_real)\n",
    "    real_perda = criterio(disc_predicao_real, torch.ones_like(disc_predicao_real, device=device))\n",
    "    \n",
    "    return (real_perda + falsas_perda) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77801281",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parameters() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\2\\ipykernel_7024\\560802923.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0motimizador_GEN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGerador\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0motimizador_DISC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscriminador\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: parameters() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "otimizador_GEN = torch.optim.Adam(Gerador.parameters(), lr=0.00001)\n",
    "otimizador_DISC = torch.optim.Adam(discriminador.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f88d15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64f5dee2a2d498ebae3a81060b4dbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'otimizador_DISC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\2\\ipykernel_7024\\216350590.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m#----- TREINO DO DISCRIMINADOR ------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Zerando gradiente\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0motimizador_DISC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Cálculo da perda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'otimizador_DISC' is not defined"
     ]
    }
   ],
   "source": [
    "media_disc_perdas = []\n",
    "media_gen_perdas = []\n",
    "\n",
    "for epoca in tqdm(range(100)):\n",
    "    for img_real, _ in dataloader:\n",
    "        # Pegando o tamanho do batch\n",
    "        tam_batch = len(img_real)\n",
    "        \n",
    "        imgs_real = img_real.view(tam_batch, -1).to(device)\n",
    "        #----- TREINO DO DISCRIMINADOR ------\n",
    "        # Zerando gradiente\n",
    "        otimizador_DISC.zero_grad()\n",
    "        \n",
    "        # Cálculo da perda\n",
    "        d_perda = calc_perda_disc(discriminador, gerador, criterio, tam_batch, imgs_real)\n",
    "        \n",
    "        # Retropropagação\n",
    "        d_perda.backward(retain_graph=True)\n",
    "\n",
    "        # Passo de otimização dos pesos e viéses\n",
    "        otimizador_DISC.step()\n",
    "        \n",
    "        #----- TREINO DO GERADOR ------\n",
    "        # Zerando gradiente\n",
    "        otimizador_GEN.zero_grad()\n",
    "        \n",
    "        # Cálculo da perda\n",
    "        g_perda = calc_perda_gen(discriminador, gerador, criterio, tam_batch)\n",
    "        \n",
    "        # Retropropagação\n",
    "        g_perda.backward(retain_graph=True)\n",
    "        \n",
    "        # Passo de otimização dos pesos e viéses\n",
    "        otimizador_GEN.step()\n",
    "\n",
    "        # Adição das perdas para exibir média posteriormente\n",
    "        media_disc_perdas.append(d_loss.item())\n",
    "        media_gen_perdas.append(g_loss.item())\n",
    "        \n",
    "    if epoca % 10 == 0 and epoca != 0: \n",
    "        ruido = gerador_ruido(tam_batch, 64)\n",
    "        print(f'Epoca {epoca} | Gen Perda: {np.mean(media_gen_perdas)} | Disc Perda: {np.mean(media_disc_perdas)}')\n",
    "\n",
    "        falsas_imgs = gerador(ruido)\n",
    "\n",
    "        # Exibição das imagens geradas\n",
    "        exibir_imgs(falsas_imgs)\n",
    "\n",
    "        media_disc_perdas = []\n",
    "        media_gen_perdas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ba28ba1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3183183004.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Administrator\\AppData\\Local\\Temp\\2\\ipykernel_7024\\3183183004.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    ef exibir_imgs(imgs, num_imagens=25, dims=(1, 28, 28)):\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ef exibir_imgs(imgs, num_imagens=25, dims=(1, 28, 28)):\n",
    "    '''\n",
    "    Função para visualização de imagens. Cria um grid 5 por 5\n",
    "    para criar imagens.\n",
    "    '''\n",
    "    imgs_flat = imgs.detach().cpu().view(-1, *dims)\n",
    "    imgs_grid = make_grid(imgs_flat[:num_imagens], nrow=5)\n",
    "    plt.imshow(imgs_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d867d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190c488c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf2258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
